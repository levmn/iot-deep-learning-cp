# -*- coding: utf-8 -*-
"""1tdspx-iot-cp-02.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nDMQdTivVzgTlEcnDSn3VXAgK1-Yt3gi

### [2TDSPX] DISRUPTIVE ARCHITECTURES: IOT, IOB E GENERATIVE AI

> * RM558948 - Allan Brito Moreira
> * RM558868 Caio Liang
> * RM98276 - Levi Magni

#### Checkpoint 02 - Treinamento de redes neurais com Keras (dados tabulares)

1. **Classificação Multiclasse**

2. **Regressão**
"""

# Importando bibliotecas
import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, mean_squared_error, r2_score
from sklearn.datasets import fetch_california_housing

from keras.models import Sequential
from keras.layers import Dense
from keras.utils import to_categorical

""" ### **Classificação Multiclasse**

 Dataset utilizado: [Wine dataset (UCI)](https://archive.ics.uci.edu/dataset/109/wine)

##### **1. Treinar uma rede neural em Keras para classificar vinhos em 3 classes.**
  - Configuração mínima: 2 camadas ocultas com 32 neurônios cada, função de ativação ReLU.
  - Camada de saída com 3 neurônios, função de ativação Softmax.
  - Função de perda: categorical_crossentropy.
  - Otimizador: Adam
"""

# Carregar o conjunto de dados
url = "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data"
column_names = ['Class', 'Alcohol', 'Malic_acid', 'Ash', 'Alcalinity_of_ash', 'Magnesium',
                'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols', 'Proanthocyanins',
                'Color_intensity', 'Hue', 'OD280_OD315_of_diluted_wines', 'Proline']
data = pd.read_csv(url, header=None, names=column_names)

data.head()

data.Class

# Seleção das features:
X = data.iloc[:, 1:]

X.shape

X.head()

# Dados da coluna target:
y = data['Class']

y

# Converter as classes para começar do 0 (0, 1, 2) em vez de (1, 2, 3)
y = y - 1

# Usando o Label Encoder para converter colunas categóricas em numéricas
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(y)
y

# Separação de dados de treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Normalização dos dados
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Converter labels para categorical (one-hot encoding)
y_train_categorical = to_categorical(y_train, num_classes=3)
y_test_categorical = to_categorical(y_test, num_classes=3)

# Construção do modelo
my_nn = Sequential()

X.shape[1]

# Criando primeira camada oculta
my_nn.add(Dense(32, input_dim=13, activation='relu'))

# Segunda camada oculta
my_nn.add(Dense(32, activation='relu'))

# Camada de saída (3 neurônios, função de ativação softmax)
my_nn.add(Dense(3, activation='softmax'))

my_nn.summary()

# Compilar o modelo
my_nn.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])

# Treinamento do modelo
history = my_nn.fit(X_train_scaled, y_train_categorical, epochs=100, batch_size=32, validation_data=(X_test_scaled, y_test_categorical), verbose=1)

# Avaliação do modelo
test_loss, test_accuracy = my_nn.evaluate(X_test_scaled, y_test_categorical, verbose=0)
print(f"Acurácia no conjunto de teste: {test_accuracy:.4f}")

"""##### **2. Comparar os resultados com um modelo do scikit-learn (RandomForestClassifier).**"""

# Treinando modelo RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train_scaled, y_train)

# Predições Random Forest
y_pred_rf = rf_model.predict(X_test_scaled)

# Avaliar o modelo
accuracy_rf = accuracy_score(y_test, y_pred_rf)
print(f"Acurácia do Random Forest: {accuracy_rf:.4f}")

# Comparar os resultados
print("Comparação de resultados:")
print(f"Acurácia da rede neural em Keras: {test_accuracy:.4f}")
print(f"Acurácia do RandomForestClassifier: {accuracy_rf:.4f}")

"""##### **3. Registrar métricas de acurácia e discutir qual modelo teve melhor desempenho.**

  > Acurácia da rede neural em Keras: `1.0000`

  > Acurácia do RandomForestClassifier: `1.0000`

  Ambos os modelos (rede neural em Keras e RandomForestClassifier) alcançaram 100% de acurácia no conjunto de teste para este dataset específico. Isso indica que ambos os modelos foram capazes de classificar corretamente todas as instâncias no conjunto de teste.

### **Regressão**

Dataset utilizado: [California Housing dataset (scikit-learn)](https://scikit-learn.org/stable/datasets/real_world.html#california-housing-dataset)

1. Treinar uma rede neural em Keras para prever o valor médio das casas.
    - Configuração mínima: 3 camadas ocultas com 64, 32 e 16 neurônios, função de ativação ReLU.
    - Camada de saída com 1 neurônio, função de ativação Linear.
    - Função de perda: mse.
    - Otimizador: Adam.
"""

# Carregar o conjunto de dados
housing = fetch_california_housing()
X_housing = pd.DataFrame(housing.data, columns=housing.feature_names)
y_housing = housing.target

X_housing.head()

X_housing.shape

y_housing.shape

# Informações sobre o target
print("Valor médio das casas (target):")
print(f"Mínimo: ${y_housing.min():.2f}")
print(f"Máximo: ${y_housing.max():.2f}")
print(f"Média: ${y_housing.mean():.2f}")

# Separação de dados de treino e teste
X_train_housing, X_test_housing, y_train_housing, y_test_housing = train_test_split(X_housing, y_housing, test_size=0.2, random_state=42)

X_train_housing.shape

X_test_housing.shape

# Normalização dos dados
scaler_housing = StandardScaler()
X_train_housing_scaled = scaler_housing.fit_transform(X_train_housing)
X_test_housing_scaled = scaler_housing.transform(X_test_housing)

# Construção do modelo
my_nn_regression = Sequential()

# 1ª camada oculta: 64 neurônios
my_nn_regression.add(Dense(64, input_dim=8, activation='relu'))

# 2ª camada oculta: 32 neurônios
my_nn_regression.add(Dense(32, activation='relu'))

# 3ª camada oculta: 16 neurônios
my_nn_regression.add(Dense(16, activation='relu'))

# Camada de saída com 1 neurônio, função de ativação Linear
my_nn_regression.add(Dense(1, activation='linear'))

my_nn_regression.summary()

# Compilar o modelo
my_nn_regression.compile(optimizer='adam', loss='mse', metrics=['mae'])

# Treinamento do modelo
history_regression = my_nn_regression.fit(X_train_housing_scaled, y_train_housing, epochs=100, batch_size=32,
                                          validation_data=(X_test_housing_scaled, y_test_housing), verbose=1)

# Avaliação da rede neural
test_loss_regression, test_mae_regression = my_nn_regression.evaluate(X_test_housing_scaled, y_test_housing, verbose=0)
print(f"MSE da rede neural: {test_loss_regression:.4f}")
print(f"MAE da rede neural: {test_mae_regression:.4f}")

# Predições da rede neural
y_pred_nn_regression = my_nn_regression.predict(X_test_housing_scaled)
r2_nn = r2_score(y_test_housing, y_pred_nn_regression)
print(f"R² da rede neural: {r2_nn:.4f}")

"""##### **2. Comparar os resultados com um modelo do scikit-learn (LinearRegression).**"""

# Treinando modelo LinearRegression
lr_regression = LinearRegression()
lr_regression.fit(X_train_housing_scaled, y_train_housing)

# Predições LinearRegression
y_pred_lr_regression = lr_regression.predict(X_test_housing_scaled)
mse_lr = mean_squared_error(y_test_housing, y_pred_lr_regression)
r2_lr = r2_score(y_test_housing, y_pred_lr_regression)
print(f"MSE da LinearRegression: {mse_lr:.4f}")
print(f"R² da LinearRegression: {r2_lr:.4f}")

# RMSE da rede neural
rmse_nn = np.sqrt(test_loss_regression)
print(f"RMSE da Rede Neural: {rmse_nn:.4f}")

# RMSE da LinearRegression
rmse_lr = np.sqrt(mse_lr)
print(f"RMSE da Linear Regression: {rmse_lr:.4f}")

# Comparar os resultados
print("Comparação de resultados:")
print(f"Acurácia da rede neural MSE: {test_loss_regression:.4f}, RMSE: {rmse_nn:.4f}, R²: {r2_nn:.4f}")
print(f"Acurácia do LinearRegression: {mse_lr:.4f}, RMSE: {rmse_lr:.4f}, R²: {r2_lr:.4f}")

"""##### **3. Registrar métricas de erro (RMSE ou MAE) e discutir qual modelo teve melhor desempenho.**

**Métricas de erro:**

* Rede neural em Keras:
    * MSE: `0.2629`
    * RMSE: `0.5127`
    * MAE: `0.3345`
    * R²: `0.7994`

* LinearRegression (scikit-learn):
    * MSE: `0.5559`
    * RMSE: `0.7456`
    * MAE: `0.5955`
    * R²: `0.5758`

**Desempenho:**

Ao comparar as métricas de erro para os modelos de regressão, podemos observar que a rede neural em Keras apresentou um desempenho significativamente melhor do que o modelo de LinearRegression.

* **MSE (Mean Squared Error) e RMSE (Root Mean Squared Error):**
  * Tanto o MSE quanto o RMSE da rede neural (`0.2629` e `0.5127`, respectivamente) são consideravelmente menores do que os da LinearRegression (`0.5559` e `0.7456`). Esses métricas penalizam erros maiores, e os valores mais baixos para a rede neural indicam que suas previsões estão, em média, mais próximas dos valores reais e com menos erros grandes.

* **MAE (Mean Absolute Error):**
  * O MAE da rede neural (`0.3345`) também é menor do que o da LinearRegression (`0.5955`). O MAE fornece uma medida da magnitude média dos erros, e o valor menor para a rede neural confirma sua maior precisão nas previsões.

* **R² (Coefficient of Determination):**
  * O valor de R² para a rede neural (`0.7994`) é substancialmente mais alto do que o da LinearRegression (`0.5758`). O R² indica a proporção da variância na variável dependente que é previsível a partir das variáveis independentes. Um R² mais próximo de 1 indica que o modelo explica uma maior proporção da variabilidade dos dados.

Com base nessas métricas, a rede neural em Keras demonstrou ter um desempenho superior na tarefa de prever o valor médio das casas neste dataset, com erros de previsão menores e uma maior capacidade de explicar a variância nos dados.
"""